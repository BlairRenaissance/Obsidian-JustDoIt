
# Blinn Phong



# 伽马校正

#### 显示设备非线性

在数字成像的早期，大多数显示器是阴极射线管（CRT）显示器。这类显示器有一个物理特性：输入电压翻倍并不会使亮度翻倍。输入电压翻倍时，亮度的实际变化遵循一个指数关系，其指数值约为2.2，称为显示器的伽马值。巧合的是，这一关系也与人眼感知亮度的方式（类似的反向幂关系）高度吻合。为了更好地理解这一点，请看下图：

![](https://learnopengl-cn.github.io/img/05/02/gamma_correction_brightness.png)

顶部的亮度梯度在人眼看来是正确的——亮度从0.1增加到0.2时，人眼会感觉亮度确实翻倍，且梯度变化均匀。然而，当讨论 **光的物理亮度（如光子数量）** 时，底部的梯度才是正确的，亮度翻倍对应物理亮度的真实翻倍。但**由于人眼对暗色变化更敏感**，这种线性梯度看起来反而不自然。

由于人眼偏好顶部梯度的亮度表现，显示器（至今仍）使用γ≈2.2的幂关系来调暗输出颜色，从而将原始的物理亮度映射到非线性的顶部梯度亮度（从上图中的下面一行转变成上面一行）。这种处理既保留了暗部细节，又优化了数据存储效率，是数字成像系统的关键技术基础。

#### 校正计算

伽马校正的核心思想是，在最终颜色输出到显示器前应用显示器伽马曲线的**倒数**进行校正（即伽马校正会使其变亮），从而抵消显示器的非线性，实现平衡。

![](https://learnopengl-cn.github.io/img/05/02/gamma_correction_gamma_curves.png)

例如，以暗红色`(0.5, 0.0, 0.0)`为例。在输出到显示器前，我们先对颜色值应用伽马校正曲线。显示器的线性颜色通常按2.2次幂缩放，因此校正需按1/2.2次幂处理。校正后的暗红色变为：

$(0.5,0.0,0.0)^{1/2.2}=(0.5,0.0,0.0)^{0.45}≈(0.73,0.0,0.0)$

当该颜色输入显示器后，显示器的伽马曲线会将其转换回：

$(0.73,0.0,0.0)^{2.2}≈(0.5,0.0,0.0)$

通过1/2.2的伽马校正，显示器最终正确显示了应用程序中线性设置的颜色。伽马值2.2是默认值，对应大多数显示器的平均伽马，由于不同显示器的伽马曲线存在差异，游戏通常允许玩家调整伽马设置。

在OpenGL中实现伽马校正的两种方法：
1. **使用内置的sRGB帧缓冲**：通过启用`GL_FRAMEBUFFER_SRGB`，OpenGL会自动对后续绘制的颜色进行伽马校正。
```C++
    glEnable(GL_FRAMEBUFFER_SRGB);
```
	此方法由硬件实现，效率高，但需注意仅在最终输出阶段启用，避免中间计算被错误处理。
    
2. **在片段着色器中手动校正**：在着色器末尾对颜色应用幂函数。
```
    float gamma = 2.2;
    FragColor.rgb = pow(fragColor.rgb, vec3(1.0/gamma));
```
    此方法需对每个最终输出的片段着色器添加校正代码。更高效的方式是在后处理阶段统一校正。

#### 伽马空间

伽马空间特指经过γ=1/2.2编码的非线性色彩空间（即上图上面那根虚线）。

**伽马空间的本质特征**

数学定义：经过γ=1/2.2（约0.4545）的幂函数编码的非线性色彩空间。
数据范围：8位色深下，实际存储值=pow(线性光, 1/2.2)。
视觉特性：暗部数据占比78%（0-127对应0-0.218线性亮度）。

**典型应用场景对比**

| 场景    | 处理方式     | 颜色空间        | 典型γ值    | 目的       |
| ----- | -------- | ----------- | ------- | -------- |
| 图像存储  | 伽马编码(校正) | 线性空间 → 伽马空间 | γ=1/2.2 | 优化存储效率   |
| 渲染计算  | 线性空间保持   | 线性空间        | -       | 物理正确性    |
| 显示器输出 | 伽马解码     | 伽马空间 → 线性空间 | γ=2.2   | 补偿显示器非线性 |

**数值示例验证**

| 存储值（伽马空间） | 显示亮度（线性空间）      | 亮度占比  |
| --------- | --------------- | ----- |
| 0.5       | 0.5^2.2 ≈ 0.218 | 21.8% |
| 0.73      | 0.73^2.2 ≈ 0.5  | 50%   |
| 1.0       | 1.0^2.2 = 1.0   | 100%  |

**现代工作流中的特殊情形**

HDR内容：使用PQ曲线或HLG替代传统伽马。
线性工作流：要求美术资产在导入时声明色彩空间。
硬件加速：GPU通过sRGB纹理格式自动转换。

#### Unity 中的色彩空间

在Unity中，色彩空间的选择（Gamma或Linear）对渲染管线的处理方式有着重要的影响。具体来说，选择Gamma色彩空间和Linear色彩空间会影响颜色的处理和显示方式。

**Gamma色彩空间**

当在Unity中选择Gamma色彩空间时，Unity会假设所有的颜色数据已经在Gamma空间中，并且不会对这些数据进行线性化处理。Gamma色彩空间的工作方式如下：

1. **输入颜色**：假设所有输入的颜色（如纹理、光照颜色等）已经在Gamma空间中。
2. **着色器处理**：在Gamma色彩空间中，着色器处理的颜色数据直接使用Gamma空间的颜色值。
3. **输出颜色**：在片段着色器中输出的颜色值不会进行额外的Gamma校正，因为假设这些颜色值已经是Gamma空间的颜色。

**Linear色彩空间**

当在Unity中选择Linear色彩空间时，Unity会进行更多的处理来确保颜色数据在渲染过程中保持线性。Linear色彩空间的工作方式如下：

1. **输入颜色**：Unity会将所有输入的颜色（如纹理、光照颜色等）从Gamma空间转换到线性空间。这通常通过Gamma解码（Gamma to Linear）来实现。
2. **着色器处理**：在Linear色彩空间中，着色器处理的颜色数据是在线性空间中的。这确保了颜色混合和光照计算的准确性。
3. **输出颜色**：在片段着色器中输出的颜色值**会在最终输出到屏幕之前进行Gamma编码**（Linear to Gamma），以确保在显示器上显示的颜色是正确的。

#### sRGB纹理

sRGB是反应真实世界中伽马值近似为2.2的CRT显示器的效果，在这个效果下输出的纹理都是sRGB。由于艺术家看着电脑屏幕创作，其绘制的图像实际上都处于sRGB空间（==**因为显示屏输出的颜色挺暗的，纹理中想调亮的地方艺术家已经修改颜色给它调亮了，相当于手动抵消过显示屏的影响了**==）。如果在渲染中使用伽马校正（如OpenGL启用 `GL_FRAMEBUFFER_SRGB` 或Unity注明全局线性空间），而不标明使用的是sRGB纹理，会被自动应用伽马校正，则会导致颜色被双重校正（如下图所示）。
  
![](https://learnopengl-cn.github.io/img/05/02/gamma_correction_srgbtextures.png)

解决方案：在加载sRGB纹理时，使用OpenGL的`GL_SRGB`或`GL_SRGB_ALPHA`格式，OpenGL会自动将其转换为线性空间。
``` C++
glTexImage2D(GL_TEXTURE_2D, 0, GL_SRGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);
```
==⚠️ **注意**：法线贴图、高光贴图等本就在线性空间的纹理，不应标记为sRGB格式。==

#### 光照衰减

真实世界中，光强衰减遵循平方反比定律：$I∝\frac1{r^2}$​。即光的衰减与距离平方成反比：
``` 
float attenuation = 1.0 / (distance * distance);
```

如果在伽马空间直接计算衰减（即输出前不会再进行对结果的gamma校正），受显示器非线性影响，实际衰减公式变为 $(1/r^{2})^{2.2}=1/r^{4.4}$​，导致衰减远快于预期（下图左上），因此通常改用线性衰减（下图左下）：
```
float attenuation = 1.0 / distance;
```

如果先换算到线性空间再进行计算，则平方衰减反而更符合物理规律（下图右上），而线性衰减会显得过弱（下图右下）。
```
// 将r从伽马空间解码到线性空间进行计算
float linearR = pow(r, 2.2);
float attenuation = 1.0 / (linearR * linearR);
vec3  finalColor = pow(textureColor * lightColor * attenuation, 1/2.2); // 线性空间的结果在输出前进行一次gamma校正
```
  
![](https://learnopengl-cn.github.io/img/05/02/gamma_correction_attenuation.png)


# 阴影映射 Shadow

阴影映射(Shadow Mapping)背后的思路非常简单：我们以光的位置为视角进行渲染，我们能看到的东西都将被点亮，看不见的一定是在阴影之中了。

## 深度贴图

第一步我们需要生成一张深度贴图(Depth Map)。深度贴图是从光的方向渲染的深度纹理，用它计算阴影。因为我们需要将场景的渲染结果储存到一个纹理中，我们需要新建一个帧缓冲。

```c++
GLuint depthMapFBO;
glGenFramebuffers(1, &depthMapFBO);

const GLuint SHADOW_WIDTH = 1024, SHADOW_HEIGHT = 1024;

GLuint depthMap;
glGenTextures(1, &depthMap);
glBindTexture(GL_TEXTURE_2D, depthMap);
glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT, 
             SHADOW_WIDTH, SHADOW_HEIGHT, 0, GL_DEPTH_COMPONENT, GL_FLOAT, NULL);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); 
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
```

生成深度贴图不太复杂。因为我们只关心深度值，我们要把纹理格式指定为GL_DEPTH_COMPONENT。我们还要把纹理的高宽设置为1024：这是深度贴图的分辨率。

把生成的深度纹理作为帧缓冲的深度缓冲：

```c++
glBindFramebuffer(GL_FRAMEBUFFER, depthMapFBO);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, depthMap, 0);
glDrawBuffer(GL_NONE);
glReadBuffer(GL_NONE);
glBindFramebuffer(GL_FRAMEBUFFER, 0);
```

我们需要的只是在从光的透视图下渲染场景的时候深度信息，所以颜色缓冲没有用。然而，不包含颜色缓冲的帧缓冲对象是不完整的，所以我们需要显式告诉OpenGL我们不适用任何颜色数据进行渲染 —— 我们通过将调用 `glDrawBuffer` 和 `glReadBuffer` 把读和绘制缓冲设置为 `GL_NONE` 来做这件事。

### 光源空间的变换

**因为我们使用的是一个所有光线都平行的定向光，所以我们将为光源使用正交投影矩阵**，透视图将没有任何变形：

```c++
GLfloat near_plane = 1.0f, far_plane = 7.5f;
glm::mat4 lightProjection = glm::ortho(-10.0f, 10.0f, -10.0f, 10.0f, near_plane, far_plane);
```

为了将每个物体变换到从光源视角可见的空间中，我们将使用glm::lookAt函数，这次从光源的位置看向场景中央：

```c++
// glm::lookAt(cameraPos, centerPos, cameraUp);
glm::mat4 lightView = glm::lookAt(glm::vec3(-2.0f, 4.0f, -1.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f));
```

二者相结合为我们提供了一个光空间的变换矩阵，它将每个世界空间坐标变换到光源处所见到的那个空间；这正是我们渲染深度贴图所需要的。

```c++
glm::mat4 lightSpaceMatrix = lightProjection * lightView;
```

### 渲染至深度贴图

当我们以光的透视图进行场景渲染的时候，我们会用一个比较简单的着色器，这个着色器除了把顶点变换到光空间以外，不会做得更多了：

```c++
#version 330 core
layout (location = 0) in vec3 position;

uniform mat4 lightSpaceMatrix;
uniform mat4 model;

void main()
{
    gl_Position = lightSpaceMatrix * model * vec4(position, 1.0f);
}
```

由于我们没有颜色缓冲，最后的片段不需要任何处理，所以我们可以简单地使用一个空片段着色器：

```c++
#version 330 core

void main()
{             
    // gl_FragDepth = gl_FragCoord.z;
}
```

这个空片段着色器什么也不干，运行完后，深度缓冲会被更新。我们可以取消那行的注释，来显式设置深度，但是这个（指注释掉那行之后）是更有效率的，因为底层无论如何都会默认去设置深度缓冲。

使用上述着色器，就可以完成深度贴图的渲染：

```c++
simpleDepthShader.Use();

/*
 * 第一个参数是Uniform Location
 * 第二个参数是Count，指定要修改的矩阵数量。如果目标统一变量不是矩阵数组，则该值应为 1；如果它是矩阵数组，则该值应为 1 或更多。
 * 第三个参数是布尔值transpose，指定在将值加载到统一变量中时是否转置矩阵。
 * 第四个参数是const GLfloat * value，是一个指向数据起始位置的指针。下面展示了两种获取方法。
 * 注意：第四个参数这里不能使用&model。（矩阵数据的指针vs.对象的地址）
   在 C++ 中，glm::mat4 是一个对象，它包含了矩阵的数据。对象的地址 &model 是 glm::mat4 对象在内存中的起始地址。这个地址指向的是整个对象，而不仅仅是矩阵数据。
   glm::value_ptr(model) 返回一个指向矩阵数据的指针，这个指针可以直接传递给 OpenGL 函数。
   glUniformMatrix4fv 函数期望接收一个指向矩阵数据的指针，而不是一个指向 glm::mat4 对象的指针。glm::mat4 对象可能包含额外的元数据或方法，而不仅仅是矩阵数据本身。因此，直接使用 &model 会导致错误。
 * 正确的用法需要使用 glm::value_ptr 函数来获取矩阵数据的指针，或者使用 &model[0][0] 获取矩阵数据的首地址，这个地址可以直接传递给 OpenGL 函数。
 */
glUniformMatrix4fv(lightSpaceMatrixLocation, 1, GL_FALSE, glm::value_ptr(lightSpaceMatrix));

glViewport(0, 0, SHADOW_WIDTH, SHADOW_HEIGHT); // 注意这里给viewport设置成了阴影贴图的大小
glBindFramebuffer(GL_FRAMEBUFFER, depthMapFBO);
glClear(GL_DEPTH_BUFFER_BIT);
RenderScene(simpleDepthShader); // 使用上述着色器渲染
glBindFramebuffer(GL_FRAMEBUFFER, 0);
```

## 渲染阴影

正确地生成深度贴图以后我们就可以开始生成阴影了。在渲染接收阴影的物体时，需要检验一个fragment是否在阴影之中：

```c++
#version 330 core
layout (location = 0) in vec3 position;
layout (location = 1) in vec3 normal;
layout (location = 2) in vec2 texCoords;

out vec2 TexCoords;

out VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} vs_out;

uniform mat4 projection;
uniform mat4 view;
uniform mat4 model;
uniform mat4 lightSpaceMatrix;

void main()
{
    gl_Position = projection * view * model * vec4(position, 1.0f);
    vs_out.FragPos = vec3(model * vec4(position, 1.0));
    vs_out.Normal = transpose(inverse(mat3(model))) * normal;
    vs_out.TexCoords = texCoords;
    vs_out.FragPosLightSpace = lightSpaceMatrix * vec4(vs_out.FragPos, 1.0);
}
```

我们用同一个lightSpaceMatrix，把世界空间顶点位置转换为光空间。区别之处在于 FragPosLightSpace 这个输出向量：顶点着色器传递一个世界空间顶点位置 vs_out.FragPos 和一个光空间的 vs_out.FragPosLightSpace 给片段着色器。

当fragment在阴影中时是1.0，在阴影外是0.0。然后，diffuse和specular颜色会乘以这个阴影元素。由于阴影不会是全黑的（由于散射），我们把ambient分量从乘法中剔除。

```c++
#version 330 core
out vec4 FragColor;

in VS_OUT {
    vec3 FragPos;
    vec3 Normal;
    vec2 TexCoords;
    vec4 FragPosLightSpace;
} fs_in;

uniform sampler2D diffuseTexture;
uniform sampler2D shadowMap;

uniform vec3 lightPos;
uniform vec3 viewPos;

float ShadowCalculation(vec4 fragPosLightSpace)
{
    [...]
}

void main()
{           
    vec3 color = texture(diffuseTexture, fs_in.TexCoords).rgb;
    vec3 normal = normalize(fs_in.Normal);
    vec3 lightColor = vec3(1.0);
    // Ambient
    vec3 ambient = 0.15 * color;
    // Diffuse
    vec3 lightDir = normalize(lightPos - fs_in.FragPos);
    float diff = max(dot(lightDir, normal), 0.0);
    vec3 diffuse = diff * lightColor;
    // Specular
    vec3 viewDir = normalize(viewPos - fs_in.FragPos);
    vec3 reflectDir = reflect(-lightDir, normal);
    float spec = 0.0;
    vec3 halfwayDir = normalize(lightDir + viewDir);  
    spec = pow(max(dot(normal, halfwayDir), 0.0), 64.0);
    vec3 specular = spec * lightColor;    
    // 计算阴影
    float shadow = ShadowCalculation(fs_in.FragPosLightSpace);       
    vec3 lighting = (ambient + (1.0 - shadow) * (diffuse + specular)) * color;    

    FragColor = vec4(lighting, 1.0f);
}
```

大部分和光照重复。我们声明一个shadowCalculation函数，用它计算阴影，然后把diffuse和specular乘以(1 - 阴影元素)。

```c++
float ShadowCalculation(vec4 fragPosLightSpace)
{
    // 执行透视除法
    vec3 projCoords = fragPosLightSpace.xyz / fragPosLightSpace.w;
    // 变换到[0,1]的范围
    projCoords = projCoords * 0.5 + 0.5;
    // 采样深度贴图(使用[0,1]范围下的fragPosLight当坐标)
    float closestDepth = texture(shadowMap, projCoords.xy).r; 
    // 取得当前片段在光源视角下的深度
    float currentDepth = projCoords.z;
    // 检查当前片段是否在阴影中
    float shadow = currentDepth > closestDepth  ? 1.0 : 0.0;
    
    return shadow;
}
```

计算阴影时，首先要把光空间片段位置转换为裁切空间的标准化设备坐标。当我们在顶点着色器输出一个裁切空间顶点位置到 gl_Position 时，OpenGL会自动进行透视除法，将裁切空间坐标的范围-w到w转为-1到1。由于裁切空间的FragPosLightSpace并不会通过gl_Position传到片段着色器里，我们必须自己做透视除法。当使用正交投影矩阵，顶点w元素仍保持不变，所以这一步实际上毫无意义。可是，当使用透视投影的时候就是必须的了，所以为了保证在两种投影矩阵下都有效就得留着这行。

因为来自深度贴图的深度在0到1的范围，所以使用projCoords采样深度贴图前需要将-1到1的NDC坐标变换为0到1。`（projCoords的xyz分量都是[-1,1]，而为了和深度贴图的深度相比较，z分量需要变换到[0,1]；为了作为从深度贴图中采样的坐标，xy分量也需要变换到[0,1]。所以整个projCoords向量都需要变换到[0,1]范围。）`

## 改进阴影贴图

### 1. Shadow Acne

**问题**：由于深度贴图分辨率限制，多个片段采样同一个深度贴图纹素，导致倾斜表面出现条纹状伪影。 
![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20250220115524.png)
**解决方案**：    
- **阴影偏移（Bias）**：在比较当前片段深度与深度贴图值时，减去一个固定偏移(如 `bias = 0.005`)。
```
	float bias = 0.005; 
	float shadow = currentDepth > closestDepth + bias ? 1.0 : 0.0;
```
- **动态偏移**：根据表面法线与光源方向夹角调整偏移量：
	`float bias = max(0.05 * (1.0 - dot(normal, lightDir)), 0.005);`
![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20250220115651.png)
- **剔除正面**：绘制深度图时剔除正面，光线实际相交的面是不透明物体的背面，即使产生了Acne，也会被不透明物体正面挡住。但此方法不适用于单面几何体（如地面），需结合其他优化。如下图。
```
	glCullFace(GL_FRONT); // 渲染深度贴图时剔除正面
	glCullFace(GL_BACK);  // 恢复默认剔除背面
```
![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/Clipboard_Screenshot_1740033144.png)

### 2. 彼得潘现象 (Peter Panning)

**问题**：物体阴影与自身分离，仿佛“漂浮”。

![](https://learnopengl-cn.github.io/img/05/03/01/shadow_mapping_peter_panning.png)

**产生原因**：如下图判断地面上的“蓝点”是否在阴影里。蓝色线为深度，以蓝色虚线为例，光平面到柱子的深度值depth=3，光平面到蓝点的距离为5，当bias取2.5，蓝点沿着蓝色虚线的方向前移2.5，到了柱子前0.5的地方。判断为蓝点还能过被照亮。则导致了悬浮。（bias平面是将地板顶点沿着光平面方向平移bias后的点连成的面，所有点连起来后刚好是和地板平行）。
![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20250220143729.png)

### 3. 深度贴图过采样(Over Sampling)

**问题**：光源视锥体外区域错误采样深度值，导致异常阴影。    
**解决方案**：
- **纹理边界处理**：设置深度贴图环绕模式为 `GL_CLAMP_TO_BORDER`，边界颜色为白色（深度1.0）：
```
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);
	glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor);
```
	
- **远平面裁剪**：在着色器中检查投影坐标Z值是否超过光源远平面：
```
	if (projCoords.z > 1.0) shadow = 0.0;
```


### 4. **阴影边缘锯齿（PCF - Percentage-Closer Filtering）**

- **问题**：阴影边缘因分辨率限制呈现锯齿。
- **解决方案**：
	- **百分比渐近滤波（PCF）**：采样周围多个像素深度值并平均结果，平滑阴影边缘：
``` GLSL
	vec2 texelSize = 1.0 / textureSize(shadowMap, 0);
	for (int x = -1; x <= 1; x++) {
		for (int y = -1; y <= 1; y++) {
			float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x,y) * texelSize).r;
			shadow += currentDepth - bias > pcfDepth ? 1.0 : 0.0;
		}
	}
	shadow /= 9.0;
```
