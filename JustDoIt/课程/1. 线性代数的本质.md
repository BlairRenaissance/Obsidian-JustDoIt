## 矩阵与线性变换

线性变换之所以被称为线性，有两个条件：
1. 空间所有直线被变换之后仍然是直线。（即保持网格线平行且等距分布）
2. 空间原点的位置不发生改变。

线性变换矩阵其实可以被看作是基向量 i 和 j 经过变换之后的新坐标。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604172446.png)

假设原向量 v 和基向量 i 与 j 的关系是 `x·i + y·j = v`，向量v经过线性变换后得到的向量 v' 和新的基向量 i' 与 j' 的这个关系不会变，仍然是`x'·i' + y'·j' = v'`。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604172703.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604195641.png)


## 行列式

二维情况下，线性变换矩阵的行列式其实就等于原坐标系下的**单位面积**被变换之后的平行四边形的**面积大小**。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604202829.png)

如果行列式为0，这时是经过变换后被挤压成了面积为0的结构，意义上就是被降维了。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604202856.png)

如果行列式为负，则是经过变换之后被翻转了，比如从右手定则变成了左手定则。

至于行列式的数值计算公式，也是可以推导出的。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605163821.png)

三维情况下也是一样，行列式等于单位体积被变换之后得到的平行六面体的体积。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604203728.png)

行列式为0则意味着整个空间被压缩为零体积的东西，也就是一个平面或一条直线，甚至最极端的情况下，一个点。
此时变换矩阵必然是列相关的，因为必然存在某一列能够被其它两列线性表示。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240604204248.png)


## 逆矩阵、列空间、秩与零空间

解出 `A·x = v` 是要我们解出一个 x 在经过 A 变换之后能够和 v 重合。

如果空间在经过线性变换之后没有被压缩降维，即行列式不等于零，那么就存在一个**唯一**的逆矩阵，能把空间变换回去。也就是也存在变换A^(-1)，能够让 v 变换成和 x 重合。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605172456.png)

但是行列式为零时，A变换将空间压缩到了更低的维度上，此时没有逆变换。没有办法将一条线解压为一个平面，至少一个函数是做不到的。因为这要求将一个单独的向量变换为一组向量，而函数只能有唯一的输入值和输出值。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605172840.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605173151.png)

通常行列式等于0的话，`A·x = v` 就没有解了。

但当足够幸运时，虽然A的行列式等于0，即det(A)=0， `A·x = v` 仍然可能有解。比如经过A变换，二维空间被压缩到了一条线上，而目标v刚好在这条线上，则能解出对应的x，即还能通过对基向量（图中绿色箭头 i 和红色箭头 j ）进行缩放相加得到目标（图中黄色箭头 v ）。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605173654.png)

变换后的空间是几维的，我们就说**秩** (Rank) 是多少。所以满秩的矩阵就是不会压缩空间，行列式不为零，也就有逆矩阵。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605175552.png)

因为矩阵的列能够告诉我们基向量被变换之后的位置，变换后的基向量构成的张成空间 (the span of transformed basis vectors) 就是所有可能的变换结果。所以更精确的秩的定义是**列空间**的维数。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240605175931.png)

变换后落在零向量（原点）上的向量构成的空间被称为零空间(Null space)或核(Kernel)。如果v刚好是零向量，零空间就是方程`A·x = v`的解x。

## 非方阵

如果一个方程接受一个二维输入，给出一个三维输出，是一件很正常的事。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703212426.png)

假设变换后的二维单位向量 i 和 j 如下。这个矩阵的列空间，是三维空间中一个过原点的二维平面。但这个矩阵仍然是满秩的，因为列空间的维数和输入空间的维数相等。

![200](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703212833.png)

那么其几何意义就如下图所示：将二维空间映射到三维空间上。因为矩阵有两列表明输入空间有两个基向量，有三行表明每一个基向量在变换后都用三个独立的坐标来描述。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703212607.png)

也有从二维输入到一维输出的变换。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703214100.png)

这种变换的几何意义可以理解为，二维网格空间变换成了一维数轴。

![200](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703214557.png)

![200](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703215127.png)

也可以理解为，平面上的一条等间距的点构成的斜线，经过线性变换后，构成了仍然等间距的水平线。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703215334.png)

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703215449.png)

这种变换是由 1x2 变换矩阵表达的（当然仍然是 i 和 j 变换后的位置）。

![500](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703215601.png)



## 点积与对偶性

点积 (点乘) 的数学定义如下：

![300](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240704210129.png)

当有一个向量 v，

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705125913.png)

在经过二维到一维的线性变换时，原本的 i 和 j 变换成了同一数轴上的1和-2，向量v经过线性变换后得到的向量 v' 和新的基向量 i' 与 j' 的这个关系不会变，仍然是`x·i' + y·j' = v'`。

于是，求点积看起来和矩阵向量乘法的计算完全一致。1x2的Transform变换矩阵只是放倒了的另一个二维向量。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705130236.png)

也就是存在一种对偶性：和下图左侧这个向量做点积，或者和右侧这个1x2的Transform变换矩阵做矩阵乘法计算（也就是二维到一维的变换），数值计算结果是一致的。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705131309.png)

假设把x轴复制一份，然后保持0在原点，将它斜向放置在空间中。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705144505.png)

单纯看蓝色斜线，就是个数轴，上面的点都是用一个数字表示。因此将二维向量直接**投影**到这条数轴上，实际上就是定义了一个从二维向量到数的函数，且这个函数是线性的（任意粉色向量上等距的点集投影到蓝色斜线上之后仍然是等距的）。

再假设有一个二维向量 u，只是刚好落在斜线上0到1的单位向量的位置。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705144813.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705144924.png)

必然有一个描述这种投影变换（二维向量 u 投影成了斜线上的单位向量）的1x2变换矩阵。而这个变换矩阵该由经历同样的投影变换后的原基向量 i 和 j 的新位置 i' 和 j' 构成。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705123351.png)

因为 u 和 i 都是单位向量，因此 i 向斜线做投影，得到的其实等于 ux。也就是投影变换矩阵的第一位就是 ux。同理可得， j 向斜线做投影，得到的其实等于 uy。

所以，描述这个投影变换的1x2变换矩阵，其实就是向量 u 的坐标 \[ux, uy]。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705165109.png)

也就是说，**其它向量向斜线上做投影，等同于和斜线上的单位向量做点积！**

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705165510.png)

这就是为什么与单位向量的点积可以解读为将向量投影到单位向量所在的直线上所得到的投影长度。

![400](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705170231.png)

因此我们可以说：**点积的几何意义与投影有关**。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703212029.png)

![500](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703215828.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703215752.png)

为什么在上面几张图中，对两个向量的处理如此不同的情况下，向量的顺序对点积计算没有影响呢？

假设我们恰好有两个相等长度的向量 w 和 v，那么他们之间必然有一个对称轴。无论是 v 向 w 做垂线，还是 w 向 v 做垂线，结果是相同的。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240704205441.png)

如果把 v 的长度拉长到了2倍，对称性被破坏了。但其实显然无论是 v 向 w 做垂线，还是 w 向 v 做垂线，结果都符合`(2v) * w = 2(v * w)`。所以即使对称性被破坏了，无论是 w 向 v 做投影，还是 v 向 w 做投影，两种理解方式下，缩放向量对点积结果的影响是相同的。

**谁对谁做投影都一样。**

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703220129.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240703220202.png)



## 叉积 (叉乘)

如何计算叉积？可以把 v 看作变换后的 i，把 w 看作变换后的 j，然后计算 `[v, w]` 的[[#行列式]]就好。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725113306.png)

叉积的数值结果就是正的或负的平行四边形的面积。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705172148.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240705172226.png)

而叉乘的物理意义，是得到唯一一个与 v 和 w 垂直，长度为 v 和 w 围成的平行四边形的面积，并且遵循右手定则的向量 p。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240724213336.png)

在此之前，对偶性给了我们启发在于，每当看到一个从空间到数轴的线性变换（比如两个向量叉乘完是得到一个向量），我们都能够找到一个向量，被称为这个变换的对偶向量。使得应用线性变换和与对偶向量点乘等价。

因此，证明上述物理意义，我们的总体计划是：
1. 根据 v 和 w 定义一个三维到一维的线性变换
2. 找到它的对偶向量
3. 说明这个对偶向量就是 v ✖️ w

将向量 i j k 填充到第一列。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725152930.png)

求右侧三维矩阵行列式的过程可以看作从三维到一维的矩阵变换（变换矩阵是一个1x3的矩阵），因为这个过程是线性的，又因为对偶性，这样的矩阵变换结果等同于和一个三维向量做点积。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725113804.png)

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725120224.png)

要记得，和向量 p 做点积的意义是，向 p 做投影，再乘上 p 的长度。

![500](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725120442.png)

而计算上面三维矩阵行列式的结果，就是计算由 v w 以及(x, y, z)组成的平行六面体的体积。获取 v 和 w 确定的平行四边形的面积，乘以向量 (x, y, z) 在垂直于平行四边形方向上的分量获得。

这和垂直于 v 和 w 且长度为平行四边形面积的向量与(x, y, z)点乘是同一回事。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725144504.png)

所以，v 和 w 的叉积等同于向量 p。

![](https://raw.githubusercontent.com/BlairRenaissance/ImageHost/main/20240725151748.png)


## 基变换

Mathematics is the art of giving the same name to different things. 🎨
数学是一门赋予不同事物相同名称的艺术。🎨

